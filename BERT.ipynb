{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import TFBertModel, BertTokenizer, BertConfig\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)\n",
    "\n",
    "#from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "#policy = mixed_precision.Policy('float32')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          text_clean  \n",
       "0  our deeds are the reason of this earthquake ma...  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  all residents asked to shelter in place are be...  \n",
       "3  13000 people receive wildfires evacuation orde...  \n",
       "4  just got sent this photo from ruby alaska as s...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_train_bert.csv')\n",
    "#df.drop(['id','keyword','location'],axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = df.text_clean.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    our deeds are the reason of this earthquake ma...\n",
       "1                forest fire near la ronge sask canada\n",
       "2    all residents asked to shelter in place are be...\n",
       "3    13000 people receive wildfires evacuation orde...\n",
       "4    just got sent this photo from ruby alaska as s...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = seq.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(df),seq))\n",
    "M = np.zeros((len(df),seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ligne in enumerate(df.text_clean):\n",
    "    tokens = tokenizer.encode_plus(ligne, max_length=seq,truncation=True, padding=\"max_length\",\n",
    "                  add_special_tokens=True,return_token_type_ids=False,\n",
    "                  return_attention_mask=True, return_tensors='tf')\n",
    "    X[i,:], M[i,:] = tokens.input_ids, tokens.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  101.,  2256., 15616.,  2024.,  1996.,  3114.,  1997.,  2023.,\n",
       "        8372.,  2089., 16455.,  9641.,  2149.,  2035.,   102.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "           0.,     0.,     0.,     0.,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.keras.utils.to_categorical(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor_df = tf.data.Dataset.from_tensor_slices((X, df.target.values.astype(float)))\n",
    "tensor_df = tf.data.Dataset.from_tensor_slices((X,M, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[  101.  2256. 15616.  2024.  1996.  3114.  1997.  2023.  8372.  2089.\n",
      " 16455.  9641.  2149.  2035.   102.     0.     0.     0.     0.     0.\n",
      "     0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "     0.], shape=(31,), dtype=float64)\n",
      "tf.Tensor(\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.], shape=(31,), dtype=float64)\n",
      "tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for X,M, labels in tensor_df.take(1):\n",
    "    print(X)\n",
    "    print(M)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_func(input_id,mask,labels):\n",
    "    return{'input_id':input_id,'mask':mask}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_df = tensor_df.map(dict_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAKE_SIZE = int(0.7*df.shape[0])\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data = tensor_df.take(TAKE_SIZE).shuffle(TAKE_SIZE)\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "val_data = tensor_df.skip(TAKE_SIZE).shuffle(df.shape[0]-TAKE_SIZE)\n",
    "val_data = val_data.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_id': <tf.Tensor: shape=(16, 31), dtype=float64, numpy=\n",
      "array([[  101.,  2210., 16216., 19665., 10720.,  2378.,  1999.,  2026.,\n",
      "         3871.,  1045.,  3092.,  2039.,  5094.,  2032.,  2041.,  1045.,\n",
      "         6878.,  2002.,  2453., 19549.,  2226.,   102.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  2329.,  8670.,  3489.,  2125.,  2001.,  2307.,  3492.,\n",
      "        26316.,  5312.,  8494., 14540.,  5178.,   102.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  2047.,  7738., 18907., 22148.,  3221.,  3898., 16167.,\n",
      "         2143.,  2005., 25935.,  1062., 10790.,  2440.,  3191., 23471.,\n",
      "          102.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  1045.,  9530., 10841.,  2099.,  1996.,  2936.,  2017.,\n",
      "         5247.,  2007.,  2115.,  2775.,  1996.,  2062.,  7386.,  3461.,\n",
      "         2243.,   102.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  5641., 17134.,  7610., 17760.,  4633., 17680.,  2053.,\n",
      "        17760.,  4633.,  2003.,  3517.,  2012.,  2023.,  2051.,   102.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  1037.,  5506., 25539.,  1996.,  8293.,  1997.,  2088.,\n",
      "         2162.,  1045.,  1998.,  1996.,  7859.,  1997.,  1996.,   102.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  2061.,  4315., 17440., 10609.,  2818., 10665.,  2003.,\n",
      "         4658.,  2005., 10425.,  1045.,  4687.,  2065.,  1045.,  2064.,\n",
      "         2448.,  2009.,  2000.,  2424., 29324.,  1999.,  5841.,  2445.,\n",
      "         2000., 24501.,  4226.,  2205.,   102.,     0.,     0.],\n",
      "       [  101.,  1045.,  3246.,  2009., 15811.,  2802.,  1996.,  2878.,\n",
      "         5353.,  1045.,  3246.,  2009., 14295.,  1998.,  1996.,  9445.,\n",
      "         9541.,  2015.,  2468.,  2741., 11638.,   102.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  2004.,  2662.,  8769.,  7385.,  3224.,  2326.,  4165.,\n",
      "         1996.,  8598.,  2055.,  9249.,  4803.,  3748., 10273.,  5366.,\n",
      "          102.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  2079.,  2017.,  2113.,  1996.,  5057.,  2933.,  2012.,\n",
      "         2115., 16165.,  2065.,  2025.,  3198.,  2115., 12366.,  2030.,\n",
      "         3136.,  3208.,  7027.,   102.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  2003.,  2115.,  2136.,  3201.,  2005.,  1037.,  3019.,\n",
      "         7071.,  1037.,  6355.,  7396.,  2030.,  2373.,  2041.,  4270.,\n",
      "         3967.,  3201., 29525.,  2000.,  2640.,   102.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101., 24471., 20755.,  2074., 27885., 22779.,  9250.,  1037.,\n",
      "         3598.,   102.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101., 10650.,  8945.,  3683., 11077.,  2213., 21496.,  3713.,\n",
      "         2039., 21318.,  2072.,  2097.,  2191.,  2469.,  2016.,  3632.,\n",
      "         2000.,  2082.,  6697.,   102.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  1045.,  9554.,  2730.,  2019.,  6584.,  2154., 10245.,\n",
      "         9039.,  1998.,  2085.,  1045., 10587.,  9554.,  2991.,  2125.,\n",
      "         1037.,  7656.,   102.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101.,  2049.,  7847.,  2666.,  2053.,  9541.,  2080.,  1045.,\n",
      "         2471., 12805.,  2017.,  2320., 27793.,   102.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
      "            0.,     0.,     0.,     0.,     0.,     0.,     0.],\n",
      "       [  101., 10397.,  2008.,  2017.,  2024.,  2183.,  2000.,  3280.,\n",
      "         2003.,  1996.,  2190.,  2126.,  1045.,  2113.,  2000.,  4468.,\n",
      "         1996.,  8132.,  1997.,  3241.,  2017.,  2031.,  2242.,  2000.,\n",
      "         4558.,  1057.,  2080.,  3889.,  5841.,   102.,     0.]])>, 'mask': <tf.Tensor: shape=(16, 31), dtype=float64, numpy=\n",
      "array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])>}\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(16, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for train,label in train_data.take(1):\n",
    "    print(train)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFBertModel.from_pretrained('bert-base-uncased',output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "=================================================================\n",
      "Total params: 109,482,240\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def model():\n",
    "    input_ids = tf.keras.layers.Input(shape=(seq,), name='input_id', dtype='int64')\n",
    "    mask = tf.keras.layers.Input(shape=(seq,), name='mask', dtype='int64')\n",
    "    embeddings = bert(input_ids,attention_mask=mask)[0]\n",
    "    \n",
    "    \n",
    "    #X = tf.keras.layers.LSTM(64, return_sequences=False)(embeddings)\n",
    "    X = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "    X = tf.keras.layers.BatchNormalization()(X)\n",
    "    X = tf.keras.layers.Dense(512, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dropout(0.5)(X)\n",
    "    X = tf.keras.layers.Dense(128, activation='relu')(X)\n",
    "    X = tf.keras.layers.Dense(32,activation='relu')(X)\n",
    "    y = tf.keras.layers.Dense(2,activation='softmax',name='outputs')(X)\n",
    "\n",
    "    return  tf.keras.Model(inputs=[input_ids,mask], outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_id (InputLayer)           [(None, 31)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (InputLayer)               [(None, 31)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_id[0][0]                   \n",
      "                                                                 mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 64)           213248      tf_bert_model[0][12]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 64)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          8320        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           4128        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 2)            66          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,708,258\n",
      "Trainable params: 225,890\n",
      "Non-trainable params: 109,482,368\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "opt = tf.keras.optimizers.Adam(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer = opt,\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=tf.keras.metrics.CategoricalAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "WARNING: AutoGraph could not transform <bound method TFBertModel.call of <transformers.models.bert.modeling_tf_bert.TFBertModel object at 0x0000021049905970>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertMainLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertMainLayer object at 0x000002104A0D1730>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method TFBertEmbeddings._embedding of <transformers.models.bert.modeling_tf_bert.TFBertEmbeddings object at 0x00000210499050D0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertEncoder.call of <transformers.models.bert.modeling_tf_bert.TFBertEncoder object at 0x000002104A0F0250>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertLayer.call of <transformers.models.bert.modeling_tf_bert.TFBertLayer object at 0x000002104A0F05E0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertAttention object at 0x000002104A0F0700>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertSelfAttention.call of <transformers.models.bert.modeling_tf_bert.TFBertSelfAttention object at 0x000002104A0F0CD0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFBertPooler.call of <transformers.models.bert.modeling_tf_bert.TFBertPooler object at 0x000002104A0F01C0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333/334 [============================>.] - ETA: 0s - loss: 0.5416 - categorical_accuracy: 0.7505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 39s 79ms/step - loss: 0.5415 - categorical_accuracy: 0.7505 - val_loss: 0.4672 - val_categorical_accuracy: 0.7912\n",
      "Epoch 2/40\n",
      "334/334 [==============================] - 23s 69ms/step - loss: 0.4694 - categorical_accuracy: 0.8002 - val_loss: 0.5070 - val_categorical_accuracy: 0.7456\n",
      "Epoch 3/40\n",
      "334/334 [==============================] - 23s 69ms/step - loss: 0.4422 - categorical_accuracy: 0.8070 - val_loss: 0.4227 - val_categorical_accuracy: 0.8144\n",
      "Epoch 4/40\n",
      "334/334 [==============================] - 22s 67ms/step - loss: 0.4534 - categorical_accuracy: 0.8056 - val_loss: 0.4280 - val_categorical_accuracy: 0.8157\n",
      "Epoch 5/40\n",
      "334/334 [==============================] - 23s 68ms/step - loss: 0.4490 - categorical_accuracy: 0.8092 - val_loss: 0.4393 - val_categorical_accuracy: 0.8165\n",
      "Epoch 6/40\n",
      "334/334 [==============================] - 23s 69ms/step - loss: 0.4264 - categorical_accuracy: 0.8187 - val_loss: 0.4225 - val_categorical_accuracy: 0.8148\n",
      "Epoch 7/40\n",
      " 29/334 [=>............................] - ETA: 15s - loss: 0.4529 - categorical_accuracy: 0.7827"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "   Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 768, 64, 1, 31, 16, 64] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_42754]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-dfe9b47b0e09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 _r=1):\n\u001b[0;32m   1131\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1132\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    823\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2969\u001b[0m       (graph_function,\n\u001b[0;32m   2970\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2971\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2972\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1945\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1946\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1947\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1948\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1949\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    557\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:    Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 2, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 768, 64, 1, 31, 16, 64] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[Adam/gradients/PartitionedCall]] [Op:__inference_train_function_42754]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data,validation_data=val_data,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve = history.history[\"loss\"]\n",
    "loss_val = history.history[\"val_loss\"]\n",
    "acc_curve = history.history[\"categorical_accuracy\"]\n",
    "acc_val = history.history[\"val_categorical_accuracy\"]\n",
    "\n",
    "plt.plot(loss_val,label=\"Loss_val\")\n",
    "plt.plot(loss_curve,label=\"Loss_train\")\n",
    "plt.legend()\n",
    "plt.title(\"loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(acc_val, label=\"acc_val\" )\n",
    "plt.plot(acc_curve, label=\"acc_train\" )\n",
    "plt.legend()\n",
    "plt.title(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
